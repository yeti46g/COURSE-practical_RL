{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DISPLAY=:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'bash' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.environ.get(\"DISPLAY\") is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yingg\\desktop\\myproject0\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as L\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24d343c2a58>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0').env\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape\n",
    "plt.imshow(env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = keras.models.Sequential()\n",
    "network.add(L.InputLayer(state_dim))\n",
    "network.add(L.Dense(100,activation = 'relu'))\n",
    "network.add(L.Dense(100,activation = 'relu'))\n",
    "network.add(L.Dense(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, epsilon=0):\n",
    "    q_values = network.predict(state[None])[0]\n",
    "    choice = np.random.random() > epsilon\n",
    "    if choice:\n",
    "        chosen_action = np.argmax(q_values)\n",
    "    else: \n",
    "        chosen_action = np.random.choice(n_actions)\n",
    "    return chosen_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e=0.0 tests passed\n",
      "e=0.1 tests passed\n",
      "e=0.5 tests passed\n",
      "e=1.0 tests passed\n"
     ]
    }
   ],
   "source": [
    "assert network.output_shape == (None, n_actions)\n",
    "assert network.layers[-1].activation == keras.activations.linear\n",
    "\n",
    "s = env.reset()\n",
    "assert np.shape(get_action(s)) == ()\n",
    "for eps in [0.,0.1,0.5,1.0]:\n",
    "    state_frequencies = np.bincount([get_action(s, epsilon=eps) for i in range(10000)], minlength = n_actions)\n",
    "    best_action = state_frequencies.argmax()\n",
    "    assert abs(state_frequencies[best_action] - 10000* ( 1- eps + eps / n_actions)) < 200\n",
    "    for other_action in range(n_actions):\n",
    "        if other_action != best_action:\n",
    "            assert abs(state_frequencies[other_action] - 10000 * (eps / n_actions)) < 200\n",
    "    print('e=%.1f tests passed'%eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_ph = tf.placeholder('float32', shape = (None,) + state_dim)\n",
    "actions_ph = tf.placeholder('int32', shape = [None])\n",
    "rewards_ph = tf.placeholder('float32', shape=[None])\n",
    "next_states_ph = tf.placeholder('float32', shape=(None,) + state_dim)\n",
    "is_done_ph = tf.placeholder('bool', shape = [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_qvalues = network(states_ph)\n",
    "predicted_qvalues_for_actions = tf.reduce_sum(predicted_qvalues * tf.one_hot(actions_ph, n_actions), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "predicted_next_qvalues = network(next_states_ph)\n",
    "next_state_values = tf.reduce_max(predicted_next_qvalues, axis = 1)\n",
    "target_qvalues_for_actions = rewards_ph + gamma * next_state_values\n",
    "target_qvalues_for_actions = tf.where(is_done_ph, rewards_ph, target_qvalues_for_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (predicted_qvalues_for_actions - tf.stop_gradient(target_qvalues_for_actions))**2\n",
    "loss = tf.reduce_mean(loss)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.gradients(loss, [predicted_qvalues_for_actions])[0] is not None, \"make sure you update q-values for chosen actions and not just all actions\"\n",
    "assert tf.gradients(loss, [predicted_next_qvalues])[0] is None, \"make sure you don't propagate gradient w.r.t. Q_(s',a')\"\n",
    "assert predicted_next_qvalues.shape.ndims == 2, \"make sure you predicted q-values for all actions in next state\"\n",
    "assert next_state_values.shape.ndims == 1, \"make sure you computed V(s') as maximum over just the actions axis and not all axes\"\n",
    "assert target_qvalues_for_actions.shape.ndims == 1, \"there's something wrong with target q-values, they must be a vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(t_max=1000, epsilon=0, train=False):\n",
    "    total_reward = 0\n",
    "    s = env.reset()\n",
    "    for t in range(t_max):\n",
    "        a = get_action(s, epsilon=epsilon)\n",
    "        next_s, r, done, _ = env.step(a)\n",
    "        if train:\n",
    "            sess.run(train_step,{\n",
    "                states_ph: [s], actions_ph :[a], rewards_ph: [r],\n",
    "                next_states_ph:[next_s], is_done_ph: [done]\n",
    "            })\n",
    "            \n",
    "        total_reward += r\n",
    "        s = next_s\n",
    "        if done: break\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0\tmean reward = 13.760\tepsilon = 0.500\n",
      "epoch #1\tmean reward = 14.430\tepsilon = 0.495\n",
      "epoch #2\tmean reward = 13.560\tepsilon = 0.490\n",
      "epoch #3\tmean reward = 15.400\tepsilon = 0.485\n",
      "epoch #4\tmean reward = 13.250\tepsilon = 0.480\n",
      "epoch #5\tmean reward = 13.330\tepsilon = 0.475\n",
      "epoch #6\tmean reward = 17.130\tepsilon = 0.471\n",
      "epoch #7\tmean reward = 15.170\tepsilon = 0.466\n",
      "epoch #8\tmean reward = 14.570\tepsilon = 0.461\n",
      "epoch #9\tmean reward = 16.510\tepsilon = 0.457\n",
      "epoch #10\tmean reward = 19.540\tepsilon = 0.452\n",
      "epoch #11\tmean reward = 19.680\tepsilon = 0.448\n",
      "epoch #12\tmean reward = 21.190\tepsilon = 0.443\n",
      "epoch #13\tmean reward = 37.490\tepsilon = 0.439\n",
      "epoch #14\tmean reward = 51.190\tepsilon = 0.434\n",
      "epoch #15\tmean reward = 39.450\tepsilon = 0.430\n",
      "epoch #16\tmean reward = 58.290\tepsilon = 0.426\n",
      "epoch #17\tmean reward = 65.200\tepsilon = 0.421\n",
      "epoch #18\tmean reward = 104.810\tepsilon = 0.417\n",
      "epoch #19\tmean reward = 116.690\tepsilon = 0.413\n",
      "epoch #20\tmean reward = 138.890\tepsilon = 0.409\n",
      "epoch #21\tmean reward = 193.150\tepsilon = 0.405\n",
      "epoch #22\tmean reward = 192.030\tepsilon = 0.401\n",
      "epoch #23\tmean reward = 242.430\tepsilon = 0.397\n",
      "epoch #24\tmean reward = 199.610\tepsilon = 0.393\n",
      "epoch #25\tmean reward = 190.520\tepsilon = 0.389\n",
      "epoch #26\tmean reward = 249.810\tepsilon = 0.385\n",
      "epoch #27\tmean reward = 277.320\tepsilon = 0.381\n",
      "epoch #28\tmean reward = 338.830\tepsilon = 0.377\n",
      "You win!\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    session_rewards = [generate_session(epsilon=epsilon, train=True) for _ in range(100)]\n",
    "    print('epoch #{}\\tmean reward = {:.3f}\\tepsilon = {:.3f}'.format(i,np.mean(session_rewards),epsilon))\n",
    "    \n",
    "    epsilon *=0.99\n",
    "    assert epsilon >= 1e-4, ' Make sure epsilon is always nonzero during training'\n",
    "    if np.mean(session_rewards) > 300:\n",
    "        print('You win!')\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
